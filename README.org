
* Emacs text editor package for integration with Tabby coding assistant

** Engineering thesis
Marta Borek  
/318635/  
Thesis supervisor: dr. hab. inÅ¼. Robert Nowak, prof uczelni

** Setting up Tabby server
[[https://tabby.tabbyml.com/docs/welcome/][Link to Tabby's offical guide for installation and documentation]]

* Quality measuring and testing

** Simple text similarity comparison

*** Algorithms

**** Edit-based
- Also known as Distance-Based
- Measure the minimum number of single-character operations (insertions, deletions, substitutions) required to transform one string into another.
- The more, the greater the *distance* -> worse similarity
- Best-suited for:
  - spelling corrections
  - shorter strings
  - structured strings (forms, codes, names)
- Examples (similarity metrics):
  - Hamming
  - Levenshtein
  - Damerau-Levenshtein
  - Smith-Waterman
- Actual tools:
  - [[https://docs.python.org/3/library/difflib.html#difflib.SequenceMatcher][Pythons built-in difflib's SequenceMatcher]]
  - [[https://jamesturk.github.io/jellyfish/][Jellyfish python library implementing most of the metrics]]
  - [[https://stackoverflow.com/questions/17388213/find-the-similarity-metric-between-two-strings][More resources (stack overflow thread)]]
    
**** Token-based
- Comparison based on tokens instead of single characters
- Best-suited for:
  - document level similarity
  - General semantic similarity in lonter texts
- Examples:
  - Jaccard
  - Sorensen-Dice
  - Tversky - generalization of the above two
  - [[https://www.researchgate.net/publication/299487656_Semimetric_Properties_of_Sorensen-Dice_and_Tversky_Indexes][Paper on the topic]]

**** Sequence-based
- Focused more on analyzing and comparing the entire sequence as opposed to token based algorithms where we compare tokens in the sequence
- Best-suited for:
  - identifying shared patterns
  - text with structure order
- Examples:
  - Ratcliff-Obershelp
    - [[https://github.com/ym001/distancia][Algorithm implementation in python /distancia/ package]]
  - Longest common substring/subsequence
  - Jaro-Winkler similarity

** Code Functionality similarity comparison

Based on /A systematic literature review on source code similarity measurement and clone detection M. Zakeri-Nasrabadi et al./ there is an overlap in clone code detection methods with the Simple text similarity approach.

*** Clones classification

**** Type I
Code snippets are exactly the same with the only differences in white spaces

**** Type II
- Structure remains the same
- Names of variables etc may vary

**** Type III
- Names vary
- Structural changes
- Some parts may be added/deleted/updated

**** Type IV
- Compared snippets are totally different in terms of plain text
- Their functionality is virtually the same
  
*** Detection techniques

**** Text-based
- Usually no preprocessing (apart from whitespaces/comments removal)
- Mostly for Ist and IInd types of clones
- Methods:
  - Burrows et al. (local alignment procedure, approximate string matching algorithm)
  - /NICAD/ (most-used, text normalization)
    - [[https://github.com/bumper-app/nicad][NICAD github repository]]
    - *Repo has been archived, last commits from 2015, reference links from the paper are from 2008 (?!)*
  - Cosma and Joy, tool /PlaGate/, LSA matrix)

**** Token-based
- Text converted to tokens sequences
- Sequences compared to find common subsequences
- Increased preprocessing time
- Does not fare well with type IV clones
- Methods:
  - Rehman /LSC Miner/ tool (multiple langs, focus on Java, C, C++)
  - Lopes /SourcererCC/  (C++ js, java, python)
  - /CPDP/
  - /SCSDS/ (avoids the impact of structural modifications)
  - /CP-Miner/ tool, /CloSpan/ subsequence mining algorithm
- *Most of them proposed between 2000 and 2013, so not the newest solutions*


**** Tree-based
- Source code converted to AST/parse tree
- Followed by the search for similar subtrees
- Time consuming for larger codebases
- Requires specifric parser for every language
- Matching subtrees is computationally expensive
- Accurate recognition of types I-III
- Methods:
  - /DECKARD/ - *deprecated*, python2, not functional out of the box
    - [[https://github.com/skyhover/Deckard][Deckard Github repository]]
  - /Tekchandani/ (for type IV)
  - /TECCD/ tool with /word2vec/ algorithm (ANTLR parser generator)
    - [[https://tjusail.github.io/people/papers/TECCD-%20A%20Tree%20Embedding%20Approach%20for%20Code%20Clone%20Detection.pdf][paper on tree embedding approach for code clone detection]]
  - /FAXIM/ model (mostly Java)
    - [[https://dl.acm.org/doi/10.1145/3597503.3639215][Research paper on Enhancing functional code clone detection with deep subtree interactions]]

**** Graph-based
- Program Dependance Graph created for code snippets
  - Each node are program statements
  - Edges are data or control dependencies
- Followed by comparison between the graphs
- Can identify all types of clones
- NP-complete problem
- Constructing PDG for large codebases is time-consuming and prone to errors.
- Methods

**** Learning-based
- Require large datasets of clean code, which may not be available for all languages
- Approaches based on Random Forest among the most promising ones
- [ ] Check methods from the initial paper
- [[https://github.com/microsoft/CodeBERT][CodeBERT]] pre-trained model and its [[https://github.com/microsoft/CodeBERT/tree/master/GraphCodeBERT/clonedetection][clone code detection]] functionality

**** Hybrid methods
- Combine 2 or more from the previous methods
- [[https://github.com/CGCL-codes/TreeCen][TreeCen detector]] - Tree Graph for scalable semantic detection (tree-based + learning-based method)

**** Test-based methods
- The *Black-box*-y approach
- The only one with the dynamic analysis approach
- Sample test inputs
- Runtime data collected
- Suitable for detecting type IV
- Methods:
  - /EvoSuite/ test data generation tool
    - Computationally expensive to generate test cases for different methods
    - [[https://www.evosuite.org/][EvoSuite Java tool site]]
  - [[https://ieeexplore.ieee.org/document/8550632][Paper on Test-based clone detection]]



